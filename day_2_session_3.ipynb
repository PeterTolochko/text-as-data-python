{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Dictionaries\n",
    "Authors: \"Petro Tolochko & Fabienne Lind \n",
    "Date: November 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "### Required Packages\n",
    "First, install, and import the required packages for text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/petrotolochko/miniconda3/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy in /Users/petrotolochko/miniconda3/lib/python3.11/site-packages (1.26.3)\n",
      "Collecting krippendorff\n",
      "  Downloading krippendorff-0.8.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/petrotolochko/miniconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/petrotolochko/miniconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/petrotolochko/miniconda3/lib/python3.11/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/petrotolochko/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading krippendorff-0.8.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: krippendorff\n",
      "Successfully installed krippendorff-0.8.0\n"
     ]
    }
   ],
   "source": [
    "#Make sure to install the pandas library if you haven't already, using:\n",
    "!pip install pandas numpy krippendorff\n",
    "\n",
    "import pandas as pd\n",
    "import re # regular expressions\n",
    "import numpy as np\n",
    "import krippendorff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "For this tasks, we will work with selected headlines from news articles about migration. The data set is a subset of the [REMINDER media corpus](https://doi.org/10.11587/IEGQ1B).\n",
    "\n",
    "Let's load the data first and take a look. Each row represents one news article.\n",
    "\n",
    "For our exercise, we work again with the English headlines (published in UK newspapers). \n",
    "Now, we load the data directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 500\n",
      "   Unnamed: 0  id country publication_date           source source_type  \\\n",
      "0           1   1      UK       2013-02-09     Daily Mirror       Print   \n",
      "1           4   4      UK       2012-03-16  telegraph.co.uk      Online   \n",
      "2           5   5      UK       2012-08-27  telegraph.co.uk      Online   \n",
      "3           8   8      UK       2016-12-13     mirror.co.uk      Online   \n",
      "4          11  11      UK       2016-03-03     The Guardian       Print   \n",
      "\n",
      "                                            headline  \\\n",
      "0                 Asylum girl 'fed up' in UK;\\nCOURT   \n",
      "1  Archbishop of Canterbury, Dr Rowan Williams: C...   \n",
      "2  France's 'scandalous' expulsion of Roma camps ...   \n",
      "3  Labour's stance on EU immigration is not susta...   \n",
      "4  'It was petrifying': lorry driver attacked nea...   \n",
      "\n",
      "                                         headline_mt  m_fr_eco  m_fr_lab  \\\n",
      "0                 Asylum girl 'fed up' in UK;\\nCOURT         0         0   \n",
      "1  Archbishop of Canterbury, Dr Rowan Williams: C...         0         0   \n",
      "2  France's 'scandalous' expulsion of Roma camps ...         0         1   \n",
      "3  Labour's stance on EU immigration is not susta...         0         1   \n",
      "4  'It was petrifying': lorry driver attacked nea...         0         1   \n",
      "\n",
      "   m_fr_wel  m_fr_sec  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         1         0  \n",
      "3         0         0  \n",
      "4         1         1  \n",
      "Index(['Unnamed: 0', 'id', 'country', 'publication_date', 'source',\n",
      "       'source_type', 'headline', 'headline_mt', 'm_fr_eco', 'm_fr_lab',\n",
      "       'm_fr_wel', 'm_fr_sec'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file from the URL\n",
    "articles_en = pd.read_csv(\"https://raw.githubusercontent.com/fabiennelind/text-as-data-in-R/main/data/articles_en.csv\")\n",
    "\n",
    "# Check corpus size\n",
    "corpus_size = len(articles_en)\n",
    "print(f'Corpus size: {corpus_size}')\n",
    "\n",
    "# Display the dataset\n",
    "print(articles_en.head())\n",
    "\n",
    "# Display column names\n",
    "print(articles_en.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Classification with a Dictionary\n",
    "\n",
    "For this tutorial, we like to identify all articles that mention political actors in their headlines. The salience of 'Political actors' is the concept that we like to measure with an automated text analysis method, a dictionary. As a first step, we define the concept more closely.\n",
    "\n",
    "### Concept Definition\n",
    "\n",
    "**Political actors** are here defined as political parties represented in the House of Commons between 2000 and 2017, which is the period in which the articles in our sample where published. Next to these parties, we define UK politicians with a leading role as political actors. To keep the task manageable for this exercise, we focus only on actors highly relevant between 2000 and 2017. \n",
    "\n",
    "We intend to measure the salience of political actors as simple binary variable:\n",
    "1 = At least one political actor is mentioned\n",
    "0 = No political actor is mentioned.\n",
    "\n",
    "### Dictionary creation\n",
    "\n",
    "A dictionary is a set of keywords or phrases that represent the concept of interest. \n",
    "\n",
    "We now start to collect relevant keywords for the dictionary. We start with a list of keywords that we consider most relevant. An example for a relevant keyword is \"Boris Johnson\".\n",
    "For clarity, we here work with two keyword sets: we collect the keywords related to politicians in one vector (here named `politicians`), and keywords related to political parties in another vector (here named `parties`). \n",
    "\n",
    "The keywords are written as regular expressions. A ‘regular expression’ is a pattern that describes a string. To test regular expressions quickly, visit https://regex101.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of politicians\n",
    "politicians = [\n",
    "    \"tony blair\", \n",
    "    \"gordon brown\", \n",
    "    \"david cameron\", \n",
    "    \"theresa may\", \n",
    "    \"boris johnson\", \n",
    "    \"prime minister\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of parties with a regular expression\n",
    "parties = [\n",
    "    \"conservative party\", \n",
    "    r'\\stor(y|ies)',  # raw string for regex\n",
    "    \"ukip\", \n",
    "    \"labour party\", \n",
    "    \"liberal democrats\", \n",
    "    \"scottish national party\", \n",
    "    \"green party\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions:\n",
    "\n",
    "Alternative ways to store the keywords?\n",
    "\n",
    "What other keywords are relevant to measure the concept?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we search the keyword in the headlines, we apply some pre-processing steps to the headlines. For this exercise, we designed the keywords all in lower case, so the headlines have to be lower case too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   asylum girl 'fed up' in uk;\\ncourt\n",
      "1    archbishop of canterbury, dr rowan williams: c...\n",
      "2    france's 'scandalous' expulsion of roma camps ...\n",
      "3    labour's stance on eu immigration is not susta...\n",
      "4    'it was petrifying': lorry driver attacked nea...\n",
      "Name: headline, dtype: object\n"
     ]
    }
   ],
   "source": [
    "articles_en['headline'] = articles_en['headline'].str.lower() # Convert the 'headline' column to lowercase\n",
    "\n",
    "print(articles_en['headline'].head()) # Display the first few values of the 'headline' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now search the keywords in the article headlines. The re.findall() function finds all occurrences of a keyword in the text. The function can search for regular expression. We here ask to count a pattern in the column `headline` of the dataframe `articles_en`. \n",
    "\n",
    "The patterns to count are the politician keywords and the party keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politicians_count\n",
      "0    473\n",
      "1     23\n",
      "2      4\n",
      "Name: count, dtype: int64\n",
      "parties_count\n",
      "0    478\n",
      "1     17\n",
      "2      4\n",
      "3      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to count keywords in a text\n",
    "def count_keywords(text, keywords):\n",
    "    # Count occurrences of each keyword (case-insensitive)\n",
    "    keyword_counts = [len(re.findall(rf\"(?i)\\b{keyword}\\b\", text)) for keyword in keywords]\n",
    "    return sum(keyword_counts)\n",
    "\n",
    "# Add columns for counts of politicians and parties\n",
    "articles_en['politicians_count'] = articles_en['headline'].apply(lambda x: count_keywords(x, politicians))\n",
    "articles_en['parties_count'] = articles_en['headline'].apply(lambda x: count_keywords(x, parties))\n",
    "\n",
    "# Display frequency tables for politicians_count and parties_count\n",
    "print(articles_en['politicians_count'].value_counts())\n",
    "print(articles_en['parties_count'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which keywords were found for each group for each row and create a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politicians_keywords_found\n",
      "                                 473\n",
      "theresa may                       12\n",
      "prime minister                     5\n",
      "david cameron                      5\n",
      "david cameron, prime minister      3\n",
      "boris johnson                      2\n",
      "Name: count, dtype: int64\n",
      "parties_keywords_found\n",
      "                478\n",
      "ukip             11\n",
      "\\stor(y|ies)     10\n",
      "labour party      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to find and list keywords in text\n",
    "def check_keywords(text, keywords):\n",
    "    # Find keywords that are present in the text\n",
    "    found_keywords = [keyword for keyword in keywords if re.search(rf\"(?i)\\b{keyword}\\b\", text)]\n",
    "    # Return the found keywords as a comma-separated string\n",
    "    return \", \".join(found_keywords)\n",
    "\n",
    "# Apply the function to find keywords in the 'headline' column\n",
    "articles_en['politicians_keywords_found'] = articles_en['headline'].apply(lambda x: check_keywords(x, politicians))\n",
    "articles_en['parties_keywords_found'] = articles_en['headline'].apply(lambda x: check_keywords(x, parties))\n",
    "\n",
    "# Display frequency tables for found keywords\n",
    "print(articles_en['politicians_keywords_found'].value_counts())\n",
    "print(articles_en['parties_keywords_found'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we obtained a count, that represents how often the keywords were detected per text. Since we initially proposed a simple binary measurement, we now do some recoding. \n",
    "\n",
    "We add a new column to the dataframe called `actors_d`. This column includes a 1 if at least one of all defined keywords creates a hit, and a 0 if no keyword was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'actors_d' based on conditions\n",
    "articles_en['actors_d'] = np.where(\n",
    "    (articles_en['parties_count'] >= 1) | (articles_en['politicians_count'] >= 1), 1, 0\n",
    ")\n",
    "\n",
    "# Ensure missing values in 'actors_d' are replaced with 0\n",
    "articles_en['actors_d'] = articles_en['actors_d'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our automated measurement, how many articles mention political actors in their headlines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actors_d\n",
      "0    453\n",
      "1     47\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Descriptive overview of the 'actors_d' column\n",
    "print(articles_en['actors_d'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now managed to get an automated measurement for the variable. **But how valid is this measurement?** Does our small set of keywords represent the concept adequately?\n",
    "\n",
    "A common procedure in automated content analysis is to test construct validity. We ask:\n",
    "How close is this automated measurement to a more trusted measurement: Human understanding of text.\n",
    "Let's put this to practice. \n",
    "\n",
    "## Dictionary validation with a human coded baseline\n",
    "\n",
    "To validate the dictionary, we compare the classifications of the dictionary with the classifications of human coders. \n",
    "\n",
    "We create the human coded baseline together. \n",
    "\n",
    "### Intercoder reliability test\n",
    "\n",
    "To ensure the quality of our manual coding, we first perform an intercoder reliability test. For this tutorial, we select a random set of 10 articles. In a real study the number of observations coded by several coders should be higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0    id country publication_date               source  \\\n",
      "131         375   375      UK       2006-05-24         The Guardian   \n",
      "445        1314  1314      UK       2013-07-13      telegraph.co.uk   \n",
      "408        1225  1225      UK       2005-01-25         The Guardian   \n",
      "439        1294  1294      UK       2016-05-30         Daily Mirror   \n",
      "7            16    16      UK       2017-11-02  The Daily Telegraph   \n",
      "9            23    23      UK       2001-12-01         The Guardian   \n",
      "362        1098  1098      UK       2016-02-19         mirror.co.uk   \n",
      "328        1008  1008      UK       2003-09-30         Daily Mirror   \n",
      "253         788   788      UK       2015-03-06         The Guardian   \n",
      "443        1312  1312      UK       2013-11-28  The Daily Telegraph   \n",
      "\n",
      "    source_type                                           headline  \\\n",
      "131       Print      dublin urged to translate road safety message   \n",
      "445      Online  keith vaz: immigration backlog 'totally unnacc...   \n",
      "408       Print  howard stirs up migrant storm: un and eu conde...   \n",
      "439       Print                          blair: out not the answer   \n",
      "7         Print              stowaways leap from bus into raf base   \n",
      "9         Print                 in brief: 2,745 lose asylum battle   \n",
      "362      Online  david cameron warns eu summit it's suicide to ...   \n",
      "328       Print  life jail for refugee: killed by dad for being...   \n",
      "253       Print  orange lifeboats used to return asylum seekers...   \n",
      "443       Print            boris: some people too stupid to get on   \n",
      "\n",
      "                                           headline_mt  m_fr_eco  m_fr_lab  \\\n",
      "131      Dublin urged to translate road safety message         0         1   \n",
      "445  Keith Vaz: Immigration backlog 'totally unnacc...         0         0   \n",
      "408  Howard stirs up migrant storm: UN and EU conde...         0         0   \n",
      "439                          Blair: Out not the answer         0         0   \n",
      "7                Stowaways leap from bus into RAF base         0         0   \n",
      "9                   In brief: 2,745 lose asylum battle         0         0   \n",
      "362  David Cameron warns EU summit it's suicide to ...         0         0   \n",
      "328  LIFE JAIL FOR REFUGEE: KILLED BY DAD FOR BEING...         0         1   \n",
      "253  Orange lifeboats used to return asylum seekers...         1         0   \n",
      "443            Boris: Some people too stupid to get on         1         0   \n",
      "\n",
      "     m_fr_wel  m_fr_sec  politicians_count  parties_count  \\\n",
      "131         0         1                  0              0   \n",
      "445         0         0                  0              0   \n",
      "408         0         0                  0              0   \n",
      "439         0         0                  0              0   \n",
      "7           0         1                  0              0   \n",
      "9           0         0                  0              0   \n",
      "362         1         0                  2              0   \n",
      "328         0         1                  0              0   \n",
      "253         0         0                  0              0   \n",
      "443         0         0                  0              0   \n",
      "\n",
      "        politicians_keywords_found parties_keywords_found  actors_d  \n",
      "131                                                               0  \n",
      "445                                                               0  \n",
      "408                                                               0  \n",
      "439                                                               0  \n",
      "7                                                                 0  \n",
      "9                                                                 0  \n",
      "362  david cameron, prime minister                                1  \n",
      "328                                                               0  \n",
      "253                                                               0  \n",
      "443                                                               0  \n"
     ]
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "random_state = 57\n",
    "\n",
    "# Sample 10 rows from the DataFrame\n",
    "intercoder_set = articles_en.sample(n=10, random_state=random_state)\n",
    "\n",
    "# Show the sampled DataFrame\n",
    "print(intercoder_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add an empty column called `actors_m`, so that coders can enter the manual codes. We drop all columns that are not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id actors_m                                           headline\n",
      "131   375               dublin urged to translate road safety message\n",
      "445  1314           keith vaz: immigration backlog 'totally unnacc...\n",
      "408  1225           howard stirs up migrant storm: un and eu conde...\n",
      "439  1294                                   blair: out not the answer\n",
      "7      16                       stowaways leap from bus into raf base\n",
      "9      23                          in brief: 2,745 lose asylum battle\n",
      "362  1098           david cameron warns eu summit it's suicide to ...\n",
      "328  1008           life jail for refugee: killed by dad for being...\n",
      "253   788           orange lifeboats used to return asylum seekers...\n",
      "443  1312                     boris: some people too stupid to get on\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'actors_m' initialized with empty strings\n",
    "intercoder_set['actors_m'] = \"\"\n",
    "\n",
    "# Select specific columns (id, actors_m, headline)\n",
    "intercoder_set = intercoder_set[['id', 'actors_m', 'headline']]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(intercoder_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create several duplicates of the intercoder reliability set, one for each coder. We create separate files so that coders code individually and do not peek by mistake.\n",
    "To each of these sets we add the coder name in a new column called `coder_name`.\n",
    "For this example, we now need 2 volunteers. Who would like to code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id actors_m                                           headline  \\\n",
      "131   375               dublin urged to translate road safety message   \n",
      "445  1314           keith vaz: immigration backlog 'totally unnacc...   \n",
      "408  1225           howard stirs up migrant storm: un and eu conde...   \n",
      "439  1294                                   blair: out not the answer   \n",
      "7      16                       stowaways leap from bus into raf base   \n",
      "\n",
      "    coder_name  \n",
      "131     Coder1  \n",
      "445     Coder1  \n",
      "408     Coder1  \n",
      "439     Coder1  \n",
      "7       Coder1  \n",
      "       id actors_m                                           headline  \\\n",
      "131   375               dublin urged to translate road safety message   \n",
      "445  1314           keith vaz: immigration backlog 'totally unnacc...   \n",
      "408  1225           howard stirs up migrant storm: un and eu conde...   \n",
      "439  1294                                   blair: out not the answer   \n",
      "7      16                       stowaways leap from bus into raf base   \n",
      "\n",
      "    coder_name  \n",
      "131     Coder2  \n",
      "445     Coder2  \n",
      "408     Coder2  \n",
      "439     Coder2  \n",
      "7       Coder2  \n"
     ]
    }
   ],
   "source": [
    "# For Coder 1\n",
    "intercoder_set_coder1 = intercoder_set.copy()  # Create a copy of the DataFrame\n",
    "intercoder_set_coder1['coder_name'] = \"Coder1\"  # Add the 'coder_name' column\n",
    "\n",
    "# For Coder 2\n",
    "intercoder_set_coder2 = intercoder_set.copy()  # Create a copy of the DataFrame\n",
    "intercoder_set_coder2['coder_name'] = \"Coder2\"  # Add the 'coder_name' column\n",
    "\n",
    "# Display the resulting DataFrames\n",
    "print(intercoder_set_coder1.head())\n",
    "print(intercoder_set_coder2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write and Read Google Sheets\n",
    "\n",
    "We then want to save the data sets in google sheets. Detailed instructions about the conncection of **Python** and **Google Sheets** can be found in  https://google-auth.readthedocs.io/en/master/\n",
    "https://google-auth.readthedocs.io/en/master/user-guide.html\n",
    "https://medium.com/@jb.ranchana/write-and-append-dataframes-to-google-sheets-in-python-f62479460cf0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gspread in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (6.1.4)\n",
      "Requirement already satisfied: google-auth in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (2.36.0)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from gspread) (1.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-auth) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-auth) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-auth) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2024.2.2)\n",
      "Requirement already satisfied: gspread_dataframe in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: gspread>=3.0.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from gspread_dataframe) (6.1.4)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from gspread_dataframe) (2.1.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from gspread_dataframe) (1.16.0)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from gspread>=3.0.0->gspread_dataframe) (2.36.0)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from gspread>=3.0.0->gspread_dataframe) (1.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from pandas>=0.24.0->gspread_dataframe) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from pandas>=0.24.0->gspread_dataframe) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from pandas>=0.24.0->gspread_dataframe) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from pandas>=0.24.0->gspread_dataframe) (2023.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread_dataframe) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread_dataframe) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread_dataframe) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread>=3.0.0->gspread_dataframe) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (2024.2.2)\n",
      "Requirement already satisfied: google in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (3.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from beautifulsoup4->google) (2.6)\n",
      "Requirement already satisfied: pydrive in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (1.3.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.2 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from pydrive) (2.154.0)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from pydrive) (4.1.3)\n",
      "Requirement already satisfied: PyYAML>=3.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from pydrive) (6.0.2)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-api-python-client>=1.2->pydrive) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-api-python-client>=1.2->pydrive) (2.36.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-api-python-client>=1.2->pydrive) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-api-python-client>=1.2->pydrive) (2.23.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-api-python-client>=1.2->pydrive) (4.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from oauth2client>=4.0.0->pydrive) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from oauth2client>=4.0.0->pydrive) (0.4.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from oauth2client>=4.0.0->pydrive) (4.9)\n",
      "Requirement already satisfied: six>=1.6.1 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from oauth2client>=4.0.0->pydrive) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (5.29.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.25.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.2->pydrive) (5.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=1.2->pydrive) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fabiennelind/opt/anaconda3/envs/venv/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gspread google-auth\n",
    "!pip install gspread_dataframe\n",
    "!pip install google\n",
    "!pip install pydrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
    "from google.oauth2.service_account import Credentials\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "# Define the scope of the API access\n",
    "scopes = ['https://www.googleapis.com/auth/spreadsheets',\n",
    "          'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "SERVICE_ACCOUNT_FILE = '/Users/fabiennelind/ucloud/Research/APIs/gsheets_creds.json'\n",
    "\n",
    "# Authenticate using service account\n",
    "creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scopes)\n",
    "\n",
    "# Connect to Google Sheets\n",
    "gc = gspread.authorize(creds)\n",
    "\n",
    "gauth = GoogleAuth()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now save the datasets for the intercoder reliability test as Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different methods to open a google sheet\n",
    "# open a google sheet from its name\n",
    "gs = gc.open('Text as data')\n",
    "\n",
    "# use a key (which can be extracted from the spreadsheet’s id\n",
    "#gs = gc.open_by_key('15ulUYe0zu2aDw9_PQ9f_GFQ42WwTGvmPrk5hWd53Zsk')\n",
    "\n",
    "# paste the entire spreadsheet’s url\n",
    "##gs = gc.open_by_url('https://docs.google.com/spreadsheets/d/15ulUYe0zu2aDw9_PQ9f_GFQ42WwTGvmPrk5hWd53Zsk/edit?gid=0#gid=0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a specific worksheet by name from the sheet\n",
    "worksheet1 = gs.worksheet('Sheet1')\n",
    "worksheet2 = gs.worksheet('Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data for coder 1 to dataframe\n",
    "worksheet1.clear()\n",
    "set_with_dataframe(worksheet=worksheet1, dataframe=intercoder_set_coder1, include_index=False,\n",
    "include_column_header=True, resize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data for coder 2 to dataframe\n",
    "worksheet2.clear()\n",
    "set_with_dataframe(worksheet=worksheet2, dataframe=intercoder_set_coder2, include_index=False,\n",
    "include_column_header=True, resize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready to code? We will post links for the different files. Read the column `headline`. If the headline mentions a political actor insert `1` in the column `actors_m`. Enter a `0` in `actors_m` if the headline does not mention a political actor.\n",
    "\n",
    "After you finished coding, we read all sheets back (now with manual classifications for `actors_m`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>actors_m</th>\n",
       "      <th>headline</th>\n",
       "      <th>coder_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>375</td>\n",
       "      <td>1</td>\n",
       "      <td>dublin urged to translate road safety message</td>\n",
       "      <td>Coder1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1314</td>\n",
       "      <td>0</td>\n",
       "      <td>keith vaz: immigration backlog 'totally unnacc...</td>\n",
       "      <td>Coder1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1225</td>\n",
       "      <td>1</td>\n",
       "      <td>howard stirs up migrant storm: un and eu conde...</td>\n",
       "      <td>Coder1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "      <td>blair: out not the answer</td>\n",
       "      <td>Coder1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>stowaways leap from bus into raf base</td>\n",
       "      <td>Coder1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>in brief: 2,745 lose asylum battle</td>\n",
       "      <td>Coder1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1098</td>\n",
       "      <td>1</td>\n",
       "      <td>david cameron warns eu summit it's suicide to ...</td>\n",
       "      <td>Coder1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1008</td>\n",
       "      <td>1</td>\n",
       "      <td>life jail for refugee: killed by dad for being...</td>\n",
       "      <td>Coder1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>788</td>\n",
       "      <td>1</td>\n",
       "      <td>orange lifeboats used to return asylum seekers...</td>\n",
       "      <td>Coder1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1312</td>\n",
       "      <td>1</td>\n",
       "      <td>boris: some people too stupid to get on</td>\n",
       "      <td>Coder1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id actors_m                                           headline  \\\n",
       "1    375        1      dublin urged to translate road safety message   \n",
       "2   1314        0  keith vaz: immigration backlog 'totally unnacc...   \n",
       "3   1225        1  howard stirs up migrant storm: un and eu conde...   \n",
       "4   1294        1                          blair: out not the answer   \n",
       "5     16        1              stowaways leap from bus into raf base   \n",
       "6     23        1                 in brief: 2,745 lose asylum battle   \n",
       "7   1098        1  david cameron warns eu summit it's suicide to ...   \n",
       "8   1008        1  life jail for refugee: killed by dad for being...   \n",
       "9    788        1  orange lifeboats used to return asylum seekers...   \n",
       "10  1312        1            boris: some people too stupid to get on   \n",
       "\n",
       "   coder_name  \n",
       "1      Coder1  \n",
       "2      Coder1  \n",
       "3      Coder1  \n",
       "4      Coder1  \n",
       "5      Coder1  \n",
       "6      Coder1  \n",
       "7      Coder1  \n",
       "8      Coder1  \n",
       "9      Coder1  \n",
       "10     Coder1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values from the sheet of coder 1\n",
    "intercoder_set_coder1_c = pd.DataFrame(worksheet1.get_all_values())\n",
    "\n",
    "# Use values of the first row as column names\n",
    "headers = intercoder_set_coder1_c.iloc[0].values\n",
    "intercoder_set_coder1_c.columns = headers\n",
    "intercoder_set_coder1_c.drop(index=0, axis=0, inplace=True)\n",
    "\n",
    "intercoder_set_coder1_c\n",
    "\n",
    "# convert relevant column to numeric\n",
    "intercoder_set_coder1_c['actors_m'] = pd.to_numeric(intercoder_set_coder1_c['actors_m'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>actors_m</th>\n",
       "      <th>headline</th>\n",
       "      <th>coder_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>375</td>\n",
       "      <td>1</td>\n",
       "      <td>dublin urged to translate road safety message</td>\n",
       "      <td>Coder2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1314</td>\n",
       "      <td>0</td>\n",
       "      <td>keith vaz: immigration backlog 'totally unnacc...</td>\n",
       "      <td>Coder2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1225</td>\n",
       "      <td>1</td>\n",
       "      <td>howard stirs up migrant storm: un and eu conde...</td>\n",
       "      <td>Coder2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "      <td>blair: out not the answer</td>\n",
       "      <td>Coder2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>stowaways leap from bus into raf base</td>\n",
       "      <td>Coder2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>in brief: 2,745 lose asylum battle</td>\n",
       "      <td>Coder2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1098</td>\n",
       "      <td>1</td>\n",
       "      <td>david cameron warns eu summit it's suicide to ...</td>\n",
       "      <td>Coder2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "      <td>life jail for refugee: killed by dad for being...</td>\n",
       "      <td>Coder2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>788</td>\n",
       "      <td>1</td>\n",
       "      <td>orange lifeboats used to return asylum seekers...</td>\n",
       "      <td>Coder2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1312</td>\n",
       "      <td>1</td>\n",
       "      <td>boris: some people too stupid to get on</td>\n",
       "      <td>Coder2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id actors_m                                           headline  \\\n",
       "1    375        1      dublin urged to translate road safety message   \n",
       "2   1314        0  keith vaz: immigration backlog 'totally unnacc...   \n",
       "3   1225        1  howard stirs up migrant storm: un and eu conde...   \n",
       "4   1294        1                          blair: out not the answer   \n",
       "5     16        1              stowaways leap from bus into raf base   \n",
       "6     23        1                 in brief: 2,745 lose asylum battle   \n",
       "7   1098        1  david cameron warns eu summit it's suicide to ...   \n",
       "8   1008        0  life jail for refugee: killed by dad for being...   \n",
       "9    788        1  orange lifeboats used to return asylum seekers...   \n",
       "10  1312        1            boris: some people too stupid to get on   \n",
       "\n",
       "   coder_name  \n",
       "1      Coder2  \n",
       "2      Coder2  \n",
       "3      Coder2  \n",
       "4      Coder2  \n",
       "5      Coder2  \n",
       "6      Coder2  \n",
       "7      Coder2  \n",
       "8      Coder2  \n",
       "9      Coder2  \n",
       "10     Coder2  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values from the sheet of coder 2\n",
    "intercoder_set_coder2_c = pd.DataFrame(worksheet2.get_all_values())\n",
    "\n",
    "# Use values of the first row as column names\n",
    "headers = intercoder_set_coder2_c.iloc[0].values\n",
    "intercoder_set_coder2_c.columns = headers\n",
    "intercoder_set_coder2_c.drop(index=0, axis=0, inplace=True)\n",
    "\n",
    "intercoder_set_coder2_c\n",
    "\n",
    "\n",
    "# convert relevant column to numeric\n",
    "intercoder_set_coder2_c['actors_m'] = pd.to_numeric(intercoder_set_coder2_c['actors_m'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too calculate the agreement between coders, we first restructure the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>actors_m_Coder1</th>\n",
       "      <th>actors_m_Coder2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1225</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1098</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>788</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1312</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  actors_m_Coder1  actors_m_Coder2\n",
       "0   375                1                1\n",
       "1  1314                0                0\n",
       "2  1225                1                1\n",
       "3  1294                1                1\n",
       "4    16                1                1\n",
       "5    23                1                1\n",
       "6  1098                1                1\n",
       "7  1008                1                0\n",
       "8   788                1                1\n",
       "9  1312                1                1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes on 'id' to align the codings for each coder\n",
    "\n",
    "merged_df_actors = pd.merge(intercoder_set_coder1_c[['id', 'actors_m']],\n",
    "                            intercoder_set_coder2_c[['id', 'actors_m']],\n",
    "                            on='id',\n",
    "                            suffixes=('_Coder1', '_Coder2')\n",
    "                        )\n",
    "merged_df_actors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 0, 1, 1, 1, 1, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix where rows are items and columns are coders' ratings\n",
    "ratings_actors = merged_df_actors[['actors_m_Coder1', 'actors_m_Coder2']].values.T  # Transpose to match input format\n",
    "ratings_actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate Krippendorff's alpha for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's alpha for 'actors_m': 0.6274509803921569\n"
     ]
    }
   ],
   "source": [
    "# Calculate Krippendorff's alpha for nominal data\n",
    "alpha_actors = krippendorff.alpha(reliability_data=ratings_actors, level_of_measurement='nominal')\n",
    "\n",
    "print(f\"Krippendorff's alpha for 'actors_m': {alpha_actors}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If alpha is large enough, we consider the quality of our manual coding as sufficient. We can then start with the creation of a larger manual baseline to be compared with the dictionary classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a manually coded baseline\n",
    "\n",
    "We pick 100 headlines randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "random_state = 576\n",
    "\n",
    "# Sample 10 rows from the DataFrame\n",
    "manual_set = articles_en.sample(n=100, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add again an empty column called `actors_m`, for coders to enter the manual codes. This time, we also add an empty column for the coder names. We split the work. Each of us gets some headlines to code (in a real application: each of the coders would need to take part in the intercoder test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'actors_m' initialized with empty strings\n",
    "manual_set['actors_m'] = \"\"\n",
    "manual_set['coder_name'] = \"\"\n",
    "\n",
    "# Select specific columns (id, actors_m, headline)\n",
    "manual_set = manual_set[['id', 'actors_m', 'headline', 'coder_name']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a google sheet for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a specific worksheet by name from the sheet\n",
    "worksheet3 = gs.worksheet('Sheet3')\n",
    "\n",
    "# write data to sheet\n",
    "worksheet3.clear()\n",
    "set_with_dataframe(worksheet=worksheet3, dataframe=manual_set, include_index=False,\n",
    "include_column_header=True, resize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please open the sheet in your browser. Enter a coding name (free to pick) in the column `coder_name` for a couple of rows first. Then start to enter 1 (political actor in headline mentioned) or 0 (not mentioned) in the column `actors_m` for the rows with your coding name. Our goal is to finish coding of all headlines.\n",
    "\n",
    "\n",
    "After you finish coding, we read all sheets back (now with manual classifications for `actors_m`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all values from the sheet of coder 2\n",
    "manual_set_c = pd.DataFrame(worksheet3.get_all_values())\n",
    "\n",
    "# Use values of the first row as column names\n",
    "headers = manual_set_c.iloc[0].values\n",
    "manual_set_c.columns = headers\n",
    "manual_set_c.drop(index=0, axis=0, inplace=True)\n",
    "\n",
    "manual_set_c\n",
    "\n",
    "\n",
    "# convert relevant column to numeric\n",
    "manual_set_c['actors_m'] = pd.to_numeric(manual_set_c['actors_m'], errors='coerce')\n",
    "manual_set_c['id'] = pd.to_numeric(manual_set_c['id'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create an object, where the manual and automated classifications are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>actors_m</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>headline</th>\n",
       "      <th>headline_mt</th>\n",
       "      <th>m_fr_eco</th>\n",
       "      <th>m_fr_lab</th>\n",
       "      <th>m_fr_wel</th>\n",
       "      <th>m_fr_sec</th>\n",
       "      <th>politicians_count</th>\n",
       "      <th>parties_count</th>\n",
       "      <th>politicians_keywords_found</th>\n",
       "      <th>parties_keywords_found</th>\n",
       "      <th>actors_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>UK</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>Print</td>\n",
       "      <td>theresa may's attacks on human rights laws are...</td>\n",
       "      <td>Theresa May's attacks on human rights laws are...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>theresa may</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>UK</td>\n",
       "      <td>2016-12-13</td>\n",
       "      <td>mirror.co.uk</td>\n",
       "      <td>Online</td>\n",
       "      <td>labour's stance on eu immigration is not susta...</td>\n",
       "      <td>Labour's stance on EU immigration is not susta...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>UK</td>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>Daily Mirror</td>\n",
       "      <td>Print</td>\n",
       "      <td>ad nausea;\\nvoice of the voice@mirror.co.uk</td>\n",
       "      <td>Ad nausea;\\nVOICE OF THE voice@mirror.co.uk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1430</td>\n",
       "      <td>1</td>\n",
       "      <td>1430</td>\n",
       "      <td>UK</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>telegraph.co.uk</td>\n",
       "      <td>Online</td>\n",
       "      <td>racists nearly killed ukip this week, but we l...</td>\n",
       "      <td>Racists nearly killed Ukip this week, but we l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>ukip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "      <td>UK</td>\n",
       "      <td>2014-02-11</td>\n",
       "      <td>The Daily Telegraph</td>\n",
       "      <td>Print</td>\n",
       "      <td>salmond 'not honest' about border controls;\\ns...</td>\n",
       "      <td>Salmond 'not honest' about border controls;\\nS...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>981</td>\n",
       "      <td>1</td>\n",
       "      <td>981</td>\n",
       "      <td>UK</td>\n",
       "      <td>2017-10-24</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>Print</td>\n",
       "      <td>the guardian view on universities and brexit: ...</td>\n",
       "      <td>The Guardian view on universities and Brexit: ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>371</td>\n",
       "      <td>UK</td>\n",
       "      <td>2002-12-28</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>Print</td>\n",
       "      <td>britain 'takes more refugees than is fair': un...</td>\n",
       "      <td>Britain 'takes more refugees than is fair': UN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>956</td>\n",
       "      <td>1</td>\n",
       "      <td>956</td>\n",
       "      <td>UK</td>\n",
       "      <td>2007-10-24</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>Print</td>\n",
       "      <td>europe: eu moves to bring in skilled foreign w...</td>\n",
       "      <td>Europe: EU moves to bring in skilled foreign w...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>561</td>\n",
       "      <td>1</td>\n",
       "      <td>561</td>\n",
       "      <td>UK</td>\n",
       "      <td>2000-04-20</td>\n",
       "      <td>Daily Mirror</td>\n",
       "      <td>Print</td>\n",
       "      <td>bishop: we're no racists</td>\n",
       "      <td>BISHOP: WE'RE NO RACISTS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>UK</td>\n",
       "      <td>2014-09-06</td>\n",
       "      <td>mirror.co.uk</td>\n",
       "      <td>Online</td>\n",
       "      <td>recap: riot breaks out at immigration centre a...</td>\n",
       "      <td>Recap: Riot breaks out at immigration centre a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  actors_m  Unnamed: 0 country publication_date               source  \\\n",
       "0    345         0         345      UK       2017-06-26         The Guardian   \n",
       "1      8         1           8      UK       2016-12-13         mirror.co.uk   \n",
       "2    800         1         800      UK       2013-07-29         Daily Mirror   \n",
       "3   1430         1        1430      UK       2017-09-30      telegraph.co.uk   \n",
       "4    177         1         177      UK       2014-02-11  The Daily Telegraph   \n",
       "..   ...       ...         ...     ...              ...                  ...   \n",
       "95   981         1         981      UK       2017-10-24         The Guardian   \n",
       "96   371         1         371      UK       2002-12-28         The Guardian   \n",
       "97   956         1         956      UK       2007-10-24         The Guardian   \n",
       "98   561         1         561      UK       2000-04-20         Daily Mirror   \n",
       "99    79         1          79      UK       2014-09-06         mirror.co.uk   \n",
       "\n",
       "   source_type                                           headline  \\\n",
       "0        Print  theresa may's attacks on human rights laws are...   \n",
       "1       Online  labour's stance on eu immigration is not susta...   \n",
       "2        Print        ad nausea;\\nvoice of the voice@mirror.co.uk   \n",
       "3       Online  racists nearly killed ukip this week, but we l...   \n",
       "4        Print  salmond 'not honest' about border controls;\\ns...   \n",
       "..         ...                                                ...   \n",
       "95       Print  the guardian view on universities and brexit: ...   \n",
       "96       Print  britain 'takes more refugees than is fair': un...   \n",
       "97       Print  europe: eu moves to bring in skilled foreign w...   \n",
       "98       Print                           bishop: we're no racists   \n",
       "99      Online  recap: riot breaks out at immigration centre a...   \n",
       "\n",
       "                                          headline_mt  m_fr_eco  m_fr_lab  \\\n",
       "0   Theresa May's attacks on human rights laws are...         0         0   \n",
       "1   Labour's stance on EU immigration is not susta...         0         1   \n",
       "2         Ad nausea;\\nVOICE OF THE voice@mirror.co.uk         0         0   \n",
       "3   Racists nearly killed Ukip this week, but we l...         0         0   \n",
       "4   Salmond 'not honest' about border controls;\\nS...         0         1   \n",
       "..                                                ...       ...       ...   \n",
       "95  The Guardian view on universities and Brexit: ...         0         0   \n",
       "96  Britain 'takes more refugees than is fair': UN...         0         0   \n",
       "97  Europe: EU moves to bring in skilled foreign w...         0         1   \n",
       "98                           BISHOP: WE'RE NO RACISTS         0         0   \n",
       "99  Recap: Riot breaks out at immigration centre a...         0         0   \n",
       "\n",
       "    m_fr_wel  m_fr_sec  politicians_count  parties_count  \\\n",
       "0          0         1                  1              0   \n",
       "1          0         0                  0              0   \n",
       "2          0         1                  0              0   \n",
       "3          0         0                  0              1   \n",
       "4          1         0                  0              0   \n",
       "..       ...       ...                ...            ...   \n",
       "95         1         0                  0              0   \n",
       "96         0         1                  0              0   \n",
       "97         0         0                  0              0   \n",
       "98         0         0                  0              0   \n",
       "99         0         0                  0              0   \n",
       "\n",
       "   politicians_keywords_found parties_keywords_found  actors_d  \n",
       "0                 theresa may                                1  \n",
       "1                                                            0  \n",
       "2                                                            0  \n",
       "3                                               ukip         1  \n",
       "4                                                            0  \n",
       "..                        ...                    ...       ...  \n",
       "95                                                           0  \n",
       "96                                                           0  \n",
       "97                                                           0  \n",
       "98                                                           0  \n",
       "99                                                           0  \n",
       "\n",
       "[100 rows x 18 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select and merge\n",
    "manual_set_c = manual_set_c[['id', 'actors_m']]\n",
    "articles_d_m = pd.merge(manual_set_c, articles_en, on='id')\n",
    "len(articles_d_m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare automated with manual classifications \n",
    "\n",
    "We compare the automated classification (in column `actors_d`) with the manual classifications (in column `actors_m`) we use three metrics: Recall, Precision, and F1.\n",
    "The metrics inform us about the quality of the dictionary. All three metrics range from 0 to 1. \n",
    "We assume that our manual classification identified all relevant articles (here: headlines that mention a political actor).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.76\n",
      "Recall: 0.15\n"
     ]
    }
   ],
   "source": [
    "# Calculate True Positives, False Positives, and False Negatives\n",
    "tp = ((articles_d_m['actors_m'] == 1) & (articles_d_m['actors_d'] == 1)).sum()  # True Positives\n",
    "fp = ((articles_d_m['actors_m'] == 0) & (articles_d_m['actors_d'] == 1)).sum()  # False Positives\n",
    "fn = ((articles_d_m['actors_m'] == 1) & (articles_d_m['actors_d'] == 0)).sum()  # False Negatives\n",
    "\n",
    "# Precision and Recall\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall \n",
    "\n",
    "By inspecting recall we can say how many relevant articles are retrieved by the dictionary.\n",
    "A recall of 1.0 means that our dictionary retrieved all relevant articles. \n",
    "A recall of 0.8 means that our dictionary retrieved 80% of all relevant articles. \n",
    "\n",
    "To obtain recall, we calculate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision \n",
    "\n",
    "By inspecting precision we can say how many retrieved articles are relevant.\n",
    "A precision of 1,0 means that all articles retrieved by the dictionary are relevant. \n",
    "A precision of 0.8 means that 80% of the articles that our dictionary retrieved are relevant articles. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
